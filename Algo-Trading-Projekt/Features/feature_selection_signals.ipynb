{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection for signal classification\n",
    "Here I will test which features are best to train the signals_classification_model with.\n",
    "The goal with the signals_classification_model is to correctly identify buy signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import talib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>buy_signal</th>\n",
       "      <th>sell_signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-22 00:00:00</th>\n",
       "      <td>2.141</td>\n",
       "      <td>2.194</td>\n",
       "      <td>2.133</td>\n",
       "      <td>2.185</td>\n",
       "      <td>10918.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22 04:00:00</th>\n",
       "      <td>2.185</td>\n",
       "      <td>2.202</td>\n",
       "      <td>2.185</td>\n",
       "      <td>2.198</td>\n",
       "      <td>26091.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22 08:00:00</th>\n",
       "      <td>2.198</td>\n",
       "      <td>2.208</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.192</td>\n",
       "      <td>24092.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22 12:00:00</th>\n",
       "      <td>2.192</td>\n",
       "      <td>2.201</td>\n",
       "      <td>2.147</td>\n",
       "      <td>2.151</td>\n",
       "      <td>30423.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22 16:00:00</th>\n",
       "      <td>2.151</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.142</td>\n",
       "      <td>2.165</td>\n",
       "      <td>17709.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      open   high    low  close   volume  buy_signal  \\\n",
       "datetime                                                               \n",
       "2021-10-22 00:00:00  2.141  2.194  2.133  2.185  10918.3           0   \n",
       "2021-10-22 04:00:00  2.185  2.202  2.185  2.198  26091.8           0   \n",
       "2021-10-22 08:00:00  2.198  2.208  2.182  2.192  24092.3           0   \n",
       "2021-10-22 12:00:00  2.192  2.201  2.147  2.151  30423.4           0   \n",
       "2021-10-22 16:00:00  2.151  2.183  2.142  2.165  17709.4           0   \n",
       "\n",
       "                     sell_signal  \n",
       "datetime                          \n",
       "2021-10-22 00:00:00            0  \n",
       "2021-10-22 04:00:00            0  \n",
       "2021-10-22 08:00:00            0  \n",
       "2021-10-22 12:00:00            0  \n",
       "2021-10-22 16:00:00            0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ADA_USDT_Signals.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical indicators - used ChatGPT to add all of them to the dataset. Later, I will optimize to see which ones are best.\n",
    "\n",
    "# Overlap Studies\n",
    "df['DEMA'] = talib.DEMA(df['close'], timeperiod=30)\n",
    "df['EMA'] = talib.EMA(df['close'], timeperiod=30)\n",
    "df['KAMA'] = talib.KAMA(df['close'], timeperiod=30)\n",
    "df['MA'] = talib.MA(df['close'], timeperiod=30)\n",
    "df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0.5, slowlimit=0.05)\n",
    "df['MIDPOINT'] = talib.MIDPOINT(df['close'], timeperiod=14)\n",
    "df['MIDPRICE'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=14)\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "df['SAREXT'] = talib.SAREXT(df['high'], df['low'], startvalue=0, offsetonreverse=0, accelerationinitlong=0.02,\n",
    "                            accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02,\n",
    "                            accelerationshort=0.02, accelerationmaxshort=0.2)\n",
    "df['SMA'] = talib.SMA(df['close'], timeperiod=30)\n",
    "df['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0.7)\n",
    "df['TEMA'] = talib.TEMA(df['close'], timeperiod=30)\n",
    "df['TRIMA'] = talib.TRIMA(df['close'], timeperiod=30)\n",
    "df['WMA'] = talib.WMA(df['close'], timeperiod=30)\n",
    "\n",
    "# Momentum Indicators\n",
    "df['ADX'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['ADXR'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df['AROON_DOWN'], df['AROON_UP'] = talib.AROON(df['high'], df['low'], timeperiod=14)\n",
    "df['AROONOSC'] = talib.AROONOSC(df['high'], df['low'], timeperiod=14)\n",
    "df['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "df['CCI'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['CMO'] = talib.CMO(df['close'], timeperiod=14)\n",
    "df['DX'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['MACD'], df['MACDSIGNAL'], df['MACDHIST'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df['MACDEXT'], df['MACDSIGNALEXT'], df['MACDHISTEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26,\n",
    "                                                                      slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "df['MACDFIX'], df['MACDSIGNALFIX'], df['MACDHISTFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "df['MFI'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'], timeperiod=14)\n",
    "df['MINUS_DI'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['MINUS_DM'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "df['MOM'] = talib.MOM(df['close'], timeperiod=10)\n",
    "df['PLUS_DI'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['PLUS_DM'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "df['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df['ROC'] = talib.ROC(df['close'], timeperiod=10)\n",
    "df['ROCP'] = talib.ROCP(df['close'], timeperiod=10)\n",
    "df['ROCR'] = talib.ROCR(df['close'], timeperiod=10)\n",
    "df['ROCR100'] = talib.ROCR100(df['close'], timeperiod=10)\n",
    "df['RSI'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['STOCH'], df['STOCH_SLOWD'] = talib.STOCH(df['high'], df['low'], df['close'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df['STOCHF'], df['STOCHF_FASTD'] = talib.STOCHF(df['high'], df['low'], df['close'], fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df['STOCHRSI'], df['STOCHRSI_FASTD'] = talib.STOCHRSI(df['close'], timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df['TRIX'] = talib.TRIX(df['close'], timeperiod=30)\n",
    "df['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "# Volume Indicators\n",
    "df['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "df['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "\n",
    "# Volatility Indicators\n",
    "df['ATR'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['NATR'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "\n",
    "# Price Transform\n",
    "df['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "df['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "df['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "df['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "\n",
    "# Cycle Indicators\n",
    "df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "df['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "df['HT_PHASOR_INPHASE'], df['HT_PHASOR_QUADRATURE'] = talib.HT_PHASOR(df['close'])\n",
    "df['HT_SINE'], df['HT_LEADSINE'] = talib.HT_SINE(df['close'])\n",
    "df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "\n",
    "# Statistical Functions\n",
    "df['BETA'] = talib.BETA(df['high'], df['low'], timeperiod=5)\n",
    "df['CORREL'] = talib.CORREL(df['high'], df['low'], timeperiod=30)\n",
    "df['LINEARREG'] = talib.LINEARREG(df['close'], timeperiod=14)  # Linear Regression\n",
    "df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'], timeperiod=14)\n",
    "df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'], timeperiod=14)\n",
    "df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'], timeperiod=14)\n",
    "df['STDDEV'] = talib.STDDEV(df['close'], timeperiod=5, nbdev=1)\n",
    "df['TSF'] = talib.TSF(df['close'], timeperiod=14)\n",
    "df['VAR'] = talib.VAR(df['close'], timeperiod=5, nbdev=1)\n",
    "\n",
    "# Bands\n",
    "df['BBANDS_UPPER'], df['BBANDS_MIDDLE'], df['BBANDS_LOWER'] = talib.BBANDS(df['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9083063646170443\n",
      "Precision: 0.125\n",
      "Recall: 0.012658227848101266\n",
      "F1 score: 0.022988505747126436\n",
      "ROC AUC: 0.5022017554334846\n",
      "Confusion matrix:\n",
      " [[841   7]\n",
      " [ 78   1]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['buy_signal', 'sell_signal']) \n",
    "y = df['buy_signal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")\n",
    "\n",
    "# feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "features_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:  \n",
    "Accuracy: 0.9083063646170443  \n",
    "Precision: 0.125  \n",
    "Recall: 0.012658227848101266  \n",
    "F1 score: 0.022988505747126436  \n",
    "ROC AUC: 0.5022017554334846  \n",
    "Confusion matrix:  \n",
    " [841   7]  \n",
    " [ 78   1]  \n",
    "\n",
    "First, the accuracy of the model is high, but the precision is very low and recall is extremely low. Precision is very important in this case, as correctly identifying the buy signals is the priority.\n",
    "\n",
    "Before trying to remove features I will experiment with the Random Forest classification threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8425026968716289\n",
      "Precision: 0.18691588785046728\n",
      "Recall: 0.25316455696202533\n",
      "F1 score: 0.21505376344086022\n",
      "ROC AUC: 0.7231460472892286\n",
      "Confusion matrix:\n",
      " [[761  87]\n",
      " [ 59  20]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['buy_signal', 'sell_signal']) \n",
    "y = df['buy_signal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "probabilities = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "predictions = (probabilities >= threshold).astype(int)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "roc_auc = roc_auc_score(y_test, probabilities)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")\n",
    "\n",
    "# feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "features_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Accuracy: 0.8425026968716289  \n",
    "Precision: 0.18691588785046728  \n",
    "Recall: 0.25316455696202533  \n",
    "F1 score: 0.21505376344086022  \n",
    "ROC AUC: 0.7231460472892286  \n",
    "Confusion matrix:  \n",
    " [761  87]  \n",
    " [ 59  20]  \n",
    "\n",
    "After some experimenting with the threshold, these were the best results I could get. However, the precision and recall are still far too low for the model to be useful.  \n",
    "\n",
    "#### Conclusion\n",
    "I will have to try another algorithm or change my approach. Another approach could be to instead of classifying buy signals, try to classify market condition (bearish, bullish, sideways).\n",
    "\n",
    "First, I will try a different way of generating the buy signals. The way I created the buy feature included a stop/loss and didn't allow for buy signals to be generated if a position had already been entered. My hypothesis here is that this makes it more difficult for the algorithm to detect patterns, as sometimes where the conditions are met for a buy signal to be generated are skipped, since I applied the logic of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataset where the buy signals are generated without restrictions\n",
    "df = pd.read_csv(\"ADA_USDT_Signals2.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "# Technical indicators - used ChatGPT to add all of them to the dataset. Later, I will optimize to see which ones are best.\n",
    "\n",
    "# Overlap Studies\n",
    "df['DEMA'] = talib.DEMA(df['close'], timeperiod=30)\n",
    "df['EMA'] = talib.EMA(df['close'], timeperiod=30)\n",
    "df['KAMA'] = talib.KAMA(df['close'], timeperiod=30)\n",
    "df['MA'] = talib.MA(df['close'], timeperiod=30)\n",
    "df['MAMA'], df['FAMA'] = talib.MAMA(df['close'], fastlimit=0.5, slowlimit=0.05)\n",
    "df['MIDPOINT'] = talib.MIDPOINT(df['close'], timeperiod=14)\n",
    "df['MIDPRICE'] = talib.MIDPRICE(df['high'], df['low'], timeperiod=14)\n",
    "df['SAR'] = talib.SAR(df['high'], df['low'], acceleration=0.02, maximum=0.2)\n",
    "df['SAREXT'] = talib.SAREXT(df['high'], df['low'], startvalue=0, offsetonreverse=0, accelerationinitlong=0.02,\n",
    "                            accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02,\n",
    "                            accelerationshort=0.02, accelerationmaxshort=0.2)\n",
    "df['SMA'] = talib.SMA(df['close'], timeperiod=30)\n",
    "df['T3'] = talib.T3(df['close'], timeperiod=5, vfactor=0.7)\n",
    "df['TEMA'] = talib.TEMA(df['close'], timeperiod=30)\n",
    "df['TRIMA'] = talib.TRIMA(df['close'], timeperiod=30)\n",
    "df['WMA'] = talib.WMA(df['close'], timeperiod=30)\n",
    "\n",
    "# Momentum Indicators\n",
    "df['ADX'] = talib.ADX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['ADXR'] = talib.ADXR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['APO'] = talib.APO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df['AROON_DOWN'], df['AROON_UP'] = talib.AROON(df['high'], df['low'], timeperiod=14)\n",
    "df['AROONOSC'] = talib.AROONOSC(df['high'], df['low'], timeperiod=14)\n",
    "df['BOP'] = talib.BOP(df['open'], df['high'], df['low'], df['close'])\n",
    "df['CCI'] = talib.CCI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['CMO'] = talib.CMO(df['close'], timeperiod=14)\n",
    "df['DX'] = talib.DX(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['MACD'], df['MACDSIGNAL'], df['MACDHIST'] = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df['MACDEXT'], df['MACDSIGNALEXT'], df['MACDHISTEXT'] = talib.MACDEXT(df['close'], fastperiod=12, fastmatype=0, slowperiod=26,\n",
    "                                                                      slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "df['MACDFIX'], df['MACDSIGNALFIX'], df['MACDHISTFIX'] = talib.MACDFIX(df['close'], signalperiod=9)\n",
    "df['MFI'] = talib.MFI(df['high'], df['low'], df['close'], df['volume'], timeperiod=14)\n",
    "df['MINUS_DI'] = talib.MINUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['MINUS_DM'] = talib.MINUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "df['MOM'] = talib.MOM(df['close'], timeperiod=10)\n",
    "df['PLUS_DI'] = talib.PLUS_DI(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['PLUS_DM'] = talib.PLUS_DM(df['high'], df['low'], timeperiod=14)\n",
    "df['PPO'] = talib.PPO(df['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df['ROC'] = talib.ROC(df['close'], timeperiod=10)\n",
    "df['ROCP'] = talib.ROCP(df['close'], timeperiod=10)\n",
    "df['ROCR'] = talib.ROCR(df['close'], timeperiod=10)\n",
    "df['ROCR100'] = talib.ROCR100(df['close'], timeperiod=10)\n",
    "df['RSI'] = talib.RSI(df['close'], timeperiod=14)\n",
    "df['STOCH'], df['STOCH_SLOWD'] = talib.STOCH(df['high'], df['low'], df['close'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df['STOCHF'], df['STOCHF_FASTD'] = talib.STOCHF(df['high'], df['low'], df['close'], fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df['STOCHRSI'], df['STOCHRSI_FASTD'] = talib.STOCHRSI(df['close'], timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df['TRIX'] = talib.TRIX(df['close'], timeperiod=30)\n",
    "df['ULTOSC'] = talib.ULTOSC(df['high'], df['low'], df['close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "df['WILLR'] = talib.WILLR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "\n",
    "# Volume Indicators\n",
    "df['AD'] = talib.AD(df['high'], df['low'], df['close'], df['volume'])\n",
    "df['ADOSC'] = talib.ADOSC(df['high'], df['low'], df['close'], df['volume'], fastperiod=3, slowperiod=10)\n",
    "df['OBV'] = talib.OBV(df['close'], df['volume'])\n",
    "\n",
    "# Volatility Indicators\n",
    "df['ATR'] = talib.ATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['NATR'] = talib.NATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "df['TRANGE'] = talib.TRANGE(df['high'], df['low'], df['close'])\n",
    "\n",
    "# Price Transform\n",
    "df['AVGPRICE'] = talib.AVGPRICE(df['open'], df['high'], df['low'], df['close'])\n",
    "df['MEDPRICE'] = talib.MEDPRICE(df['high'], df['low'])\n",
    "df['TYPPRICE'] = talib.TYPPRICE(df['high'], df['low'], df['close'])\n",
    "df['WCLPRICE'] = talib.WCLPRICE(df['high'], df['low'], df['close'])\n",
    "\n",
    "# Cycle Indicators\n",
    "df['HT_DCPERIOD'] = talib.HT_DCPERIOD(df['close'])\n",
    "df['HT_DCPHASE'] = talib.HT_DCPHASE(df['close'])\n",
    "df['HT_PHASOR_INPHASE'], df['HT_PHASOR_QUADRATURE'] = talib.HT_PHASOR(df['close'])\n",
    "df['HT_SINE'], df['HT_LEADSINE'] = talib.HT_SINE(df['close'])\n",
    "df['HT_TRENDMODE'] = talib.HT_TRENDMODE(df['close'])\n",
    "\n",
    "# Statistical Functions\n",
    "df['BETA'] = talib.BETA(df['high'], df['low'], timeperiod=5)\n",
    "df['CORREL'] = talib.CORREL(df['high'], df['low'], timeperiod=30)\n",
    "df['LINEARREG'] = talib.LINEARREG(df['close'], timeperiod=14)  # Linear Regression\n",
    "df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df['close'], timeperiod=14)\n",
    "df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df['close'], timeperiod=14)\n",
    "df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df['close'], timeperiod=14)\n",
    "df['STDDEV'] = talib.STDDEV(df['close'], timeperiod=5, nbdev=1)\n",
    "df['TSF'] = talib.TSF(df['close'], timeperiod=14)\n",
    "df['VAR'] = talib.VAR(df['close'], timeperiod=5, nbdev=1)\n",
    "\n",
    "# Bands\n",
    "df['BBANDS_UPPER'], df['BBANDS_MIDDLE'], df['BBANDS_LOWER'] = talib.BBANDS(df['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8295577130528586\n",
      "Precision: 0.8455882352941176\n",
      "Recall: 0.6647398843930635\n",
      "F1 score: 0.7443365695792881\n",
      "ROC AUC: 0.7962253638832788\n",
      "Confusion matrix:\n",
      " [[539  42]\n",
      " [116 230]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['buy_signal']) \n",
    "y = df['buy_signal']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Accuracy: 0.8295577130528586  \n",
    "Precision: 0.8455882352941176  \n",
    "Recall: 0.6647398843930635  \n",
    "F1 score: 0.7443365695792881  \n",
    "ROC AUC: 0.7962253638832788  \n",
    "Confusion matrix:  \n",
    " [539  42]  \n",
    " [116 230]  \n",
    "\n",
    "Ah, there we go. Much better. The precision is quite high, and a trading strategy with 85% good entries is excellent. Still, I will try other algorithms as well before I try optimizing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6353829557713053\n",
      "Precision: 0.5338983050847458\n",
      "Recall: 0.18208092485549132\n",
      "F1 Score: 0.27155172413793105\n",
      "Confusion Matrix:\n",
      "[[526  55]\n",
      " [283  63]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = logreg_model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Accuracy: 0.6353829557713053  \n",
    "Precision: 0.5338983050847458  \n",
    "Recall: 0.18208092485549132  \n",
    "F1 Score: 0.27155172413793105  \n",
    "Confusion Matrix:  \n",
    " [526  55]  \n",
    " [283  63]  \n",
    "\n",
    "Clearly Logistic Regression performed far worse than Random Forest. Next I will try SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6299892125134844\n",
      "Precision: 0.5405405405405406\n",
      "Recall: 0.057803468208092484\n",
      "F1 Score: 0.10443864229765012\n",
      "Confusion Matrix:\n",
      "[[564  17]\n",
      " [326  20]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# try linear kernel first\n",
    "svm_model = SVC(kernel=\"linear\", probability=True, random_state=42)\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.697950377562028\n",
      "Precision: 0.7619047619047619\n",
      "Recall: 0.2774566473988439\n",
      "F1 Score: 0.4067796610169492\n",
      "Confusion Matrix:\n",
      "[[551  30]\n",
      " [250  96]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# try non-linear kernel next, I'll go with RBF\n",
    "svm_model = SVC(kernel=\"rbf\", probability=True, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Accuracy: 0.697950377562028  \n",
    "Precision: 0.7619047619047619  \n",
    "Recall: 0.2774566473988439  \n",
    "F1 Score: 0.4067796610169492  \n",
    "Confusion Matrix:  \n",
    "[551  30]  \n",
    " [250  96]  \n",
    "\n",
    "\n",
    "SVM performed better with a non-linear kernal than a linear one, but the results are still worse than Random Forest. Next I'll try k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.819848975188781\n",
      "Precision: 0.7720364741641338\n",
      "Recall: 0.7341040462427746\n",
      "F1 Score: 0.7525925925925926\n",
      "Confusion Matrix:\n",
      "[[506  75]\n",
      " [ 92 254]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Accuracy: 0.819848975188781  \n",
    "Precision: 0.7720364741641338  \n",
    "Recall: 0.7341040462427746  \n",
    "F1 Score: 0.7525925925925926  \n",
    "Confusion Matrix:  \n",
    "[506  75]  \n",
    " [ 92 254]  \n",
    "\n",
    "The k-NN model performed best with n_neighbors=1, but this is likely because of how the buy signals are generated. Sometimes buy signals are generated consecutively, so this score may be deceptive. These results were slightly better than the Random Forest algorithm, but nevertheless I feel more confident in the Random Forest algorithm.\n",
    "\n",
    "### Conclusion\n",
    "After trying Random Forest, Logistic Regression, SVM and k-NN, it's either Random Forest or k-NN. I will test them both on the more recent ADAUSDT dataset to see which performs better there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recent = pd.read_csv(\"ADA_USDT_recent_Signals2.csv\")\n",
    "df_recent[\"datetime\"] = pd.to_datetime(df_recent[\"datetime\"])\n",
    "df_recent.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "# Overlap Studies\n",
    "df_recent['DEMA'] = talib.DEMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['EMA'] = talib.EMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['KAMA'] = talib.KAMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['MA'] = talib.MA(df_recent['close'], timeperiod=30)\n",
    "df_recent['MAMA'], df_recent['FAMA'] = talib.MAMA(df_recent['close'], fastlimit=0.5, slowlimit=0.05)\n",
    "df_recent['MIDPOINT'] = talib.MIDPOINT(df_recent['close'], timeperiod=14)\n",
    "df_recent['MIDPRICE'] = talib.MIDPRICE(df_recent['high'], df_recent['low'], timeperiod=14)\n",
    "df_recent['SAR'] = talib.SAR(df_recent['high'], df_recent['low'], acceleration=0.02, maximum=0.2)\n",
    "df_recent['SAREXT'] = talib.SAREXT(df_recent['high'], df_recent['low'], startvalue=0, offsetonreverse=0, accelerationinitlong=0.02,\n",
    "                            accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02,\n",
    "                            accelerationshort=0.02, accelerationmaxshort=0.2)\n",
    "df_recent['SMA'] = talib.SMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['T3'] = talib.T3(df_recent['close'], timeperiod=5, vfactor=0.7)\n",
    "df_recent['TEMA'] = talib.TEMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['TRIMA'] = talib.TRIMA(df_recent['close'], timeperiod=30)\n",
    "df_recent['WMA'] = talib.WMA(df_recent['close'], timeperiod=30)\n",
    "\n",
    "# Momentum Indicators\n",
    "df_recent['ADX'] = talib.ADX(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['ADXR'] = talib.ADXR(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['APO'] = talib.APO(df_recent['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df_recent['AROON_DOWN'], df_recent['AROON_UP'] = talib.AROON(df_recent['high'], df_recent['low'], timeperiod=14)\n",
    "df_recent['AROONOSC'] = talib.AROONOSC(df_recent['high'], df_recent['low'], timeperiod=14)\n",
    "df_recent['BOP'] = talib.BOP(df_recent['open'], df_recent['high'], df_recent['low'], df_recent['close'])\n",
    "df_recent['CCI'] = talib.CCI(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['CMO'] = talib.CMO(df_recent['close'], timeperiod=14)\n",
    "df_recent['DX'] = talib.DX(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['MACD'], df_recent['MACDSIGNAL'], df_recent['MACDHIST'] = talib.MACD(df_recent['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "df_recent['MACDEXT'], df_recent['MACDSIGNALEXT'], df_recent['MACDHISTEXT'] = talib.MACDEXT(df_recent['close'], fastperiod=12, fastmatype=0, slowperiod=26,\n",
    "                                                                      slowmatype=0, signalperiod=9, signalmatype=0)\n",
    "df_recent['MACDFIX'], df_recent['MACDSIGNALFIX'], df_recent['MACDHISTFIX'] = talib.MACDFIX(df_recent['close'], signalperiod=9)\n",
    "df_recent['MFI'] = talib.MFI(df_recent['high'], df_recent['low'], df_recent['close'], df_recent['volume'], timeperiod=14)\n",
    "df_recent['MINUS_DI'] = talib.MINUS_DI(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['MINUS_DM'] = talib.MINUS_DM(df_recent['high'], df_recent['low'], timeperiod=14)\n",
    "df_recent['MOM'] = talib.MOM(df_recent['close'], timeperiod=10)\n",
    "df_recent['PLUS_DI'] = talib.PLUS_DI(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['PLUS_DM'] = talib.PLUS_DM(df_recent['high'], df_recent['low'], timeperiod=14)\n",
    "df_recent['PPO'] = talib.PPO(df_recent['close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "df_recent['ROC'] = talib.ROC(df_recent['close'], timeperiod=10)\n",
    "df_recent['ROCP'] = talib.ROCP(df_recent['close'], timeperiod=10)\n",
    "df_recent['ROCR'] = talib.ROCR(df_recent['close'], timeperiod=10)\n",
    "df_recent['ROCR100'] = talib.ROCR100(df_recent['close'], timeperiod=10)\n",
    "df_recent['RSI'] = talib.RSI(df_recent['close'], timeperiod=14)\n",
    "df_recent['STOCH'], df_recent['STOCH_SLOWD'] = talib.STOCH(df_recent['high'], df_recent['low'], df_recent['close'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df_recent['STOCHF'], df_recent['STOCHF_FASTD'] = talib.STOCHF(df_recent['high'], df_recent['low'], df_recent['close'], fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df_recent['STOCHRSI'], df_recent['STOCHRSI_FASTD'] = talib.STOCHRSI(df_recent['close'], timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "df_recent['TRIX'] = talib.TRIX(df_recent['close'], timeperiod=30)\n",
    "df_recent['ULTOSC'] = talib.ULTOSC(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "df_recent['WILLR'] = talib.WILLR(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "\n",
    "# Volume Indicators\n",
    "df_recent['AD'] = talib.AD(df_recent['high'], df_recent['low'], df_recent['close'], df_recent['volume'])\n",
    "df_recent['ADOSC'] = talib.ADOSC(df_recent['high'], df_recent['low'], df_recent['close'], df_recent['volume'], fastperiod=3, slowperiod=10)\n",
    "df_recent['OBV'] = talib.OBV(df_recent['close'], df_recent['volume'])\n",
    "\n",
    "# Volatility Indicators\n",
    "df_recent['ATR'] = talib.ATR(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['NATR'] = talib.NATR(df_recent['high'], df_recent['low'], df_recent['close'], timeperiod=14)\n",
    "df_recent['TRANGE'] = talib.TRANGE(df_recent['high'], df_recent['low'], df_recent['close'])\n",
    "\n",
    "# Price Transform\n",
    "df_recent['AVGPRICE'] = talib.AVGPRICE(df_recent['open'], df_recent['high'], df_recent['low'], df_recent['close'])\n",
    "df_recent['MEDPRICE'] = talib.MEDPRICE(df_recent['high'], df_recent['low'])\n",
    "df_recent['TYPPRICE'] = talib.TYPPRICE(df_recent['high'], df_recent['low'], df_recent['close'])\n",
    "df_recent['WCLPRICE'] = talib.WCLPRICE(df_recent['high'], df_recent['low'], df_recent['close'])\n",
    "\n",
    "# Cycle Indicators\n",
    "df_recent['HT_DCPERIOD'] = talib.HT_DCPERIOD(df_recent['close'])\n",
    "df_recent['HT_DCPHASE'] = talib.HT_DCPHASE(df_recent['close'])\n",
    "df_recent['HT_PHASOR_INPHASE'], df_recent['HT_PHASOR_QUADRATURE'] = talib.HT_PHASOR(df_recent['close'])\n",
    "df_recent['HT_SINE'], df_recent['HT_LEADSINE'] = talib.HT_SINE(df_recent['close'])\n",
    "df_recent['HT_TRENDMODE'] = talib.HT_TRENDMODE(df_recent['close'])\n",
    "\n",
    "# Statistical Functions\n",
    "df_recent['BETA'] = talib.BETA(df_recent['high'], df_recent['low'], timeperiod=5)\n",
    "df_recent['CORREL'] = talib.CORREL(df_recent['high'], df_recent['low'], timeperiod=30)\n",
    "df_recent['LINEARREG'] = talib.LINEARREG(df_recent['close'], timeperiod=14)  # Linear Regression\n",
    "df_recent['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(df_recent['close'], timeperiod=14)\n",
    "df_recent['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(df_recent['close'], timeperiod=14)\n",
    "df_recent['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(df_recent['close'], timeperiod=14)\n",
    "df_recent['STDDEV'] = talib.STDDEV(df_recent['close'], timeperiod=5, nbdev=1)\n",
    "df_recent['TSF'] = talib.TSF(df_recent['close'], timeperiod=14)\n",
    "df_recent['VAR'] = talib.VAR(df_recent['close'], timeperiod=5, nbdev=1)\n",
    "\n",
    "# Bands\n",
    "df_recent['BBANDS_UPPER'], df_recent['BBANDS_MIDDLE'], df_recent['BBANDS_LOWER'] = talib.BBANDS(df_recent['close'], timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n",
    "\n",
    "df_recent.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6025878003696857\n",
      "Precision: 0.45569620253164556\n",
      "Recall: 0.17307692307692307\n",
      "F1 score: 0.2508710801393728\n",
      "ROC AUC: 0.5219738969738971\n",
      "Confusion matrix:\n",
      " [[290  43]\n",
      " [172  36]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "X_recent = df_recent.drop(columns=[\"buy_signal\"])\n",
    "y_recent_true = df_recent[\"buy_signal\"]\n",
    "\n",
    "y_pred = rf_model.predict(X_recent)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_recent_true, y_pred)\n",
    "precision = precision_score(y_recent_true, y_pred)\n",
    "recall = recall_score(y_recent_true, y_pred)\n",
    "f1 = f1_score(y_recent_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_recent_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5785582255083179\n",
      "Precision: 0.4484536082474227\n",
      "Recall: 0.4182692307692308\n",
      "F1 score: 0.43283582089552236\n",
      "ROC AUC: 0.5484739547239548\n",
      "Confusion matrix:\n",
      " [[226 107]\n",
      " [121  87]]\n"
     ]
    }
   ],
   "source": [
    "# k-NN\n",
    "X_recent_scaled = scaler.fit_transform(X_recent)\n",
    "\n",
    "y_pred = knn_model.predict(X_recent_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_recent_true, y_pred)\n",
    "precision = precision_score(y_recent_true, y_pred)\n",
    "recall = recall_score(y_recent_true, y_pred)\n",
    "f1 = f1_score(y_recent_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_recent_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6136783733826248\n",
      "Precision: 0.48717948717948717\n",
      "Recall: 0.09134615384615384\n",
      "F1 score: 0.15384615384615385\n",
      "ROC AUC: 0.5156430468930469\n",
      "Confusion matrix:\n",
      " [[313  20]\n",
      " [189  19]]\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "y_pred = svm_model.predict(X_recent_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_recent_true, y_pred)\n",
    "precision = precision_score(y_recent_true, y_pred)\n",
    "recall = recall_score(y_recent_true, y_pred)\n",
    "f1 = f1_score(y_recent_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_recent_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_recent_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6173752310536045\n",
      "Precision: 0.5050505050505051\n",
      "Recall: 0.2403846153846154\n",
      "F1 score: 0.3257328990228013\n",
      "ROC AUC: 0.5466187341187341\n",
      "Confusion matrix:\n",
      " [[284  49]\n",
      " [158  50]]\n"
     ]
    }
   ],
   "source": [
    "# Logarithmic Regression\n",
    "y_pred = logreg_model.predict(X_recent_scaled)\n",
    "\n",
    "# evaluation metrics\n",
    "accuracy = accuracy_score(y_recent_true, y_pred)\n",
    "precision = precision_score(y_recent_true, y_pred)\n",
    "recall = recall_score(y_recent_true, y_pred)\n",
    "f1 = f1_score(y_recent_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_recent_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_recent_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"Confusion matrix:\\n {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "Well, turns out, the models didn't work particularly well on the recent data using any of the previously used algorithms. I will have to change my approach.  \n",
    "Still, good practise and learning opportunity for a student such as myself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Algo-Trading-Projekt-KMheLDPn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
